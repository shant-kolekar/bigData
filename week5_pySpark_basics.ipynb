{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9db605",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import getpass\n",
    "username = getpass.getuser()\n",
    "spark = SparkSession. \\\n",
    "builder. \\\n",
    "config('spark.ui.port','0'). \\\n",
    "config(\"spark.sql.warehouse.dir\", f\"/user/{username}/warehouse\"). \\\n",
    "enableHiveSupport(). \\\n",
    "master('yarn'). \\\n",
    "getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acbb5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c9690b",
   "metadata": {},
   "source": [
    "# Adding headers to csv file using command line\n",
    "```bash\n",
    "\n",
    "# Creat a empty file with headers\n",
    "touch orders_header_file.txt\n",
    "\n",
    "vi orders_header_file.txt (# Go to Insert Mode (I) > Add Headers > press ESC > `:wq`\n",
    "\n",
    "cat orders_header_file.txt /public/retail_db/orders/part-00000 >> orders_wh.csv\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee44da4",
   "metadata": {},
   "source": [
    "# Read file from HDFS\n",
    "```python\n",
    "spark.read\\\n",
    ".format('csv')\\\n",
    ".option('header', 'true')\\\n",
    ".option('inferSchema', 'true')\\ # not preferred (will scan entire file to get correct data type), might infer data type incorrectly\n",
    ".load('/public/retail_db/orders/part-00000') # CSV file path in HDFS\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50766042",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_df = spark.read\\\n",
    ".format('csv')\\\n",
    ".option('header', 'true')\\\n",
    ".option('inferSchema', 'true')\\\n",
    ".load('/public/retail_db/orders/part-00000') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ed0a25",
   "metadata": {},
   "source": [
    "### Get First 20 rows of dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a4e176",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_df.show() # Optionally we can specify number of Records inside the parenthesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570fee37",
   "metadata": {},
   "source": [
    "### Get Schema of dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c45aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_df.printSchema() # Utility function to get Schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2b6818",
   "metadata": {},
   "source": [
    "### Rename column name in Spark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80239ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "renamed_df = orders_df.withColumnRenamed(\"order_status\", \"status\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5221a65",
   "metadata": {},
   "source": [
    "### Add Column: Change dataType of order_date column to_timestamp()\n",
    "\n",
    "* Since spark DFs are immutable.\n",
    "\n",
    "* In order to change the dataType we need to create new column with desired dataType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20723a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df = renamed_df.withColumn(\"order_date_new\", to_timestamp(\"order_date\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250b42f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df.printSchema()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 3",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
